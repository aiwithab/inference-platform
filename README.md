# Inference Platform Demo

A learning-based project to master backend infrastructure for ML inference services.

### Goal
Build an inference-serving platform with:
- API design (REST/gRPC)
- Model catalog & deployment automation
- Containerization (Docker)
- Orchestration (Kubernetes)
- Observability (Prometheus + Grafana)
- Caching (Redis)
- Multi-tenant & scaling architecture

### Setup
1. Clone repo
2. Run `python3 -m venv venv && source venv/bin/activate`
3. Run `docker compose up -d`
4. Confirm Postgres + Redis running.
